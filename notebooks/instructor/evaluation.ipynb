{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_jsonl, save_jsonl\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, model_validator, field_validator, Field, ValidationInfo\n",
    "from typing import List, Dict, Union, Any, Optional\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.patch(OpenAI(api_key=os.environ['OPENAI_API_KEY']))\n",
    "MODEL = \"gpt-3.5-turbo-0125\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧠 Load data\n",
    "\n",
    "- reference KBs\n",
    "- predicted KBs\n",
    "- Wikidata Properties by Usage Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kbs = read_jsonl('../../data/prediction.jsonl')\n",
    "ref_kbs = read_jsonl('../../data/wikidata_entities.jsonl')\n",
    "popular_properties = pd.read_csv('../../data/wikidata-properties-counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted KBs: 4\n",
      "Number of reference KBs: 41\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of predicted KBs: {len(pred_kbs)}\")\n",
    "print(f\"Number of reference KBs: {len(ref_kbs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align our Predicted Entities and Reference Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted KBs: 4\n",
      "Number of reference KBs: 4\n",
      "ref:  ['Barack Obama', 'Douglas Adams', 'George Washington', 'Tim Berners-Lee']\n",
      "pred:  ['Barack Obama', 'Douglas Adams', 'George Washington', 'Tim Berners-Lee']\n"
     ]
    }
   ],
   "source": [
    "# only take the predictions and references of entities that exist in both\n",
    "union_entities = set([p['entity_label'] for p in pred_kbs]).intersection(set([r['entity_label'] for r in ref_kbs]))\n",
    "\n",
    "pred_kbs = [kb for kb in pred_kbs if kb['entity_label'] in union_entities]\n",
    "pred_kbs = sorted(pred_kbs, key=lambda x: x['entity_label'])\n",
    "\n",
    "ref_kbs = [kb for kb in ref_kbs if kb['entity_label'] in union_entities]\n",
    "ref_kbs = sorted(ref_kbs, key=lambda x: x['entity_label'])\n",
    "\n",
    "print(f\"Number of predicted KBs: {len(pred_kbs)}\")\n",
    "print(f\"Number of reference KBs: {len(ref_kbs)}\")\n",
    "print(\"ref: \", [kb['entity_label'] for kb in pred_kbs])\n",
    "print(\"pred: \", [kb['entity_label'] for kb in ref_kbs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_kbs[-1]['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['entity_label', 'properties', 'chunked_content', 'QID'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_kbs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['entity_label', 'properties'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_kbs[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔎 Filter the Reference KB by the most popular Properties\n",
    "\n",
    "This is a method to constrain the y label for our model so that the task is easier.\n",
    "\n",
    "Popular properties are assigned by looking at their usage count across all of Wikidata. [This info is available here](https://www.wikidata.org/wiki/Wikidata:Database_reports/List_of_properties/all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "      <th>Data type[1]</th>\n",
       "      <th>Counts[2]</th>\n",
       "      <th>largest_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P2860</td>\n",
       "      <td>cites work</td>\n",
       "      <td>citation from one creative or scholarly work t...</td>\n",
       "      <td>WI</td>\n",
       "      <td>292,583,247 M 390 N</td>\n",
       "      <td>292583247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1545</td>\n",
       "      <td>series ordinal</td>\n",
       "      <td>position of an item in its parent series (most...</td>\n",
       "      <td>S</td>\n",
       "      <td>175,830,141 Q 2,298 N</td>\n",
       "      <td>175830141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P2093</td>\n",
       "      <td>author name string</td>\n",
       "      <td>stores unspecified author or editor name for p...</td>\n",
       "      <td>S</td>\n",
       "      <td>138,055,438 M 589,477 Q 29,173 R 213 N</td>\n",
       "      <td>138055438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P31</td>\n",
       "      <td>instance of</td>\n",
       "      <td>that class of which this subject is a particul...</td>\n",
       "      <td>WI</td>\n",
       "      <td>114,614,926 M 20 N</td>\n",
       "      <td>114614926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P248</td>\n",
       "      <td>stated in</td>\n",
       "      <td>to be used in the references field to refer to...</td>\n",
       "      <td>WI</td>\n",
       "      <td>98,211,619 R 122 Q 19 N</td>\n",
       "      <td>98211619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID               label  \\\n",
       "0  P2860          cites work   \n",
       "1  P1545      series ordinal   \n",
       "2  P2093  author name string   \n",
       "3    P31         instance of   \n",
       "4   P248           stated in   \n",
       "\n",
       "                                         description Data type[1]  \\\n",
       "0  citation from one creative or scholarly work t...           WI   \n",
       "1  position of an item in its parent series (most...            S   \n",
       "2  stores unspecified author or editor name for p...            S   \n",
       "3  that class of which this subject is a particul...           WI   \n",
       "4  to be used in the references field to refer to...           WI   \n",
       "\n",
       "                                Counts[2]  largest_number  \n",
       "0                     292,583,247 M 390 N       292583247  \n",
       "1                   175,830,141 Q 2,298 N       175830141  \n",
       "2  138,055,438 M 589,477 Q 29,173 R 213 N       138055438  \n",
       "3                      114,614,926 M 20 N       114614926  \n",
       "4                 98,211,619 R 122 Q 19 N        98211619  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(popular_properties))\n",
    "popular_properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama\n",
      "Num properties: 348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('InfluenceWatch influencer', ['person/barack-obama']),\n",
       " ('Spotify user ID', ['barackobama']),\n",
       " ('KBR person ID', ['14008887']),\n",
       " ('CiNii Research ID', ['1140000791660494336']),\n",
       " ('Deutsche Synchronkartei person ID', ['4SJPnNOfb']),\n",
       " ('ABC News topic ID', ['obama-barack']),\n",
       " ('RILM ID', ['30082']),\n",
       " ('Great Russian Encyclopedia portal ID', ['obama-barak-1d66f6']),\n",
       " ('ScienceDirect topic ID', ['computer-science/president-obama']),\n",
       " ('University of Barcelona authority ID', ['981058523280006706']),\n",
       " ('Google News topics ID',\n",
       "  ['CAAqIggKIhxDQkFTRHdvSkwyMHZNREp0YW0xeUVnSmxiaWdBUAE']),\n",
       " ('WorldCat Entities ID', ['E39PBJjCKvFkHQ3F9QhY6vw3cP']),\n",
       " ('BBC News topic ID', ['cvenzmgywl4t']),\n",
       " ('Scopus author ID', ['24587142900']),\n",
       " ('Threads username', ['barackobama'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ref_kbs[0]['entity_label'])\n",
    "print(f\"Num properties: {len(ref_kbs[0]['properties'])}\")\n",
    "list(ref_kbs[0]['properties'].items())[-30:-15] \n",
    "# there's a lot of garbage here that isn't even interesting e.g Rotten Tomatoes ID\n",
    "# but it's mixed in with the good stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num filtered properties: 37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'instance of': ['human'],\n",
       " 'sex or gender': ['male'],\n",
       " 'country of citizenship': ['United States of America', 'Kenya'],\n",
       " 'date of birth': ['+1961-08-04T00:00:00Z'],\n",
       " 'place of birth': ['Kapiolani Medical Center for Women and Children',\n",
       "  'Honolulu'],\n",
       " 'given name': ['Barack', 'Hussein'],\n",
       " 'mother': ['Stanley Ann Dunham'],\n",
       " 'father': ['Barack Obama Sr.'],\n",
       " 'spouse': ['Michelle Obama'],\n",
       " 'child': ['Sasha Obama', 'Malia Obama'],\n",
       " 'image': ['President Barack Obama.jpg'],\n",
       " 'educated at': ['State Elementary School Menteng 01',\n",
       "  'Punahou School',\n",
       "  'Occidental College',\n",
       "  'Columbia University',\n",
       "  'Harvard Law School',\n",
       "  'Noelani Elementary School',\n",
       "  'Centaurus High School',\n",
       "  'University of Chicago Law School',\n",
       "  'Harvard University',\n",
       "  'Nelson High School',\n",
       "  'King College Prep High School'],\n",
       " 'position held': ['President of the United States',\n",
       "  'member of the State Senate of Illinois',\n",
       "  'United States senator',\n",
       "  'United States senator',\n",
       "  'President-elect of the United States'],\n",
       " 'member of political party': ['Democratic Party'],\n",
       " 'occupation': ['politician',\n",
       "  'lawyer',\n",
       "  'political writer',\n",
       "  'community organizer',\n",
       "  'statesperson',\n",
       "  'jurist',\n",
       "  'podcaster',\n",
       "  'academic',\n",
       "  'memoirist',\n",
       "  'international forum participant'],\n",
       " 'employer': ['Business International Corporation',\n",
       "  'New York Public Interest Research Group',\n",
       "  'Gamaliel Foundation',\n",
       "  'Sidley Austin',\n",
       "  'University of Chicago'],\n",
       " 'award received': ['Nobel Peace Prize',\n",
       "  'Grammy Award for Best Audio Book, Narration & Storytelling Recording',\n",
       "  'Presidential Medal of Distinction',\n",
       "  'Time Person of the Year',\n",
       "  'Time Person of the Year',\n",
       "  'Grammy Award for Best Audio Book, Narration & Storytelling Recording',\n",
       "  'NAACP Image Award for Outstanding Literary Work, Nonfiction',\n",
       "  \"NAACP Image Award – Chairman's Award\",\n",
       "  'German Media Award',\n",
       "  'King Abdulaziz Medal',\n",
       "  'Order of Sikatuna',\n",
       "  'National Medal of Science',\n",
       "  'honorary doctorate from the University of Notre Dame',\n",
       "  'honorary doctor of the Northwestern University',\n",
       "  'honorary doctor of the University of Johannesburg',\n",
       "  'Order of the Rajamitrabhorn',\n",
       "  'Knight Commander of the Order of the British Empire',\n",
       "  'Romy',\n",
       "  'Primetime Emmy Award for Outstanding Narrator',\n",
       "  'Financial Times Person of the Year',\n",
       "  'Phoenix Award',\n",
       "  'Audie Award for Narration by the Author',\n",
       "  'Profile in Courage Award'],\n",
       " 'ISNI': ['0000000121331026'],\n",
       " 'Commons category': ['Barack Obama'],\n",
       " \"topic's main category\": ['Category:Barack Obama'],\n",
       " 'official website URL': ['https://barackobama.com'],\n",
       " 'family name': ['Obama'],\n",
       " 'religion or worldview': ['Protestantism',\n",
       "  'Congregational churches',\n",
       "  'congregationalist polity',\n",
       "  'United Church of Christ'],\n",
       " 'described by source': ['Lentapedia (full versions)',\n",
       "  'Lentapedia',\n",
       "  'Great Encyclopedia of Cyril and Methodius',\n",
       "  'These nine different creatures have been named after Barack Obama',\n",
       "  'Obalky knih.cz'],\n",
       " 'languages spoken, written or signed': ['English', 'Indonesian'],\n",
       " 'name in native language': [\"{'text': 'Barack Obama', 'language': 'en'}\"],\n",
       " 'academic degree': ['Bachelor of Arts', 'Juris Doctor'],\n",
       " 'significant event': ['first inauguration of Barack Obama',\n",
       "  'second inauguration of Barack Obama',\n",
       "  'Obama spying contra-Trump allegations'],\n",
       " 'sibling': ['Auma Obama',\n",
       "  'Maya Soetoro-Ng',\n",
       "  'Bernard Obama',\n",
       "  'George Hussein Onyango Obama',\n",
       "  'Mark Okoth Obama Ndesandjo',\n",
       "  'David Ndesandjo',\n",
       "  'Abo Obama',\n",
       "  'Malik Obama'],\n",
       " 'height': ['+1.85'],\n",
       " 'mass': ['+180', '+80'],\n",
       " 'member of': ['American Academy of Arts and Sciences',\n",
       "  'American Philosophical Society',\n",
       "  '109th United States Congress',\n",
       "  '110th United States Congress',\n",
       "  'Congressional Black Caucus'],\n",
       " 'described at URL': [\"http://www.treccani.it/enciclopedia/barack-obama_(Il-Libro-dell'Anno)/\",\n",
       "  'https://www.whitehouse.gov/about-the-white-house/presidents/barack-obama/'],\n",
       " 'on focus list of Wikimedia project': ['WikiProject African diaspora',\n",
       "  'Wikipedia:Vital articles/Level/4'],\n",
       " 'field of work': ['civil rights', 'constitutional law'],\n",
       " 'participant in': ['commencement at the Knox College',\n",
       "  'commencement at the University of Notre Dame',\n",
       "  'World Government Summit 2016'],\n",
       " 'social media followers': ['+129049397',\n",
       "  '+576000',\n",
       "  '+130859182',\n",
       "  '+133309684',\n",
       "  '+582000']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_ref_kb_by_top_n_wikiproperties(ref_kbs, wikiproperties, N):\n",
    "\n",
    "    filtered_ref_kbs = []\n",
    "        \n",
    "    for kb in ref_kbs:\n",
    "        properties = kb['properties']\n",
    "\n",
    "        top_N = wikiproperties.sort_values(by='largest_number', ascending=False).head(N)\n",
    "\n",
    "        top_N = top_N['label'].tolist()\n",
    "\n",
    "        kb['properties'] = {\n",
    "            key: value for key, value in properties.items() if key in top_N\n",
    "            }\n",
    "        filtered_ref_kbs.append(kb)\n",
    "    \n",
    "    return filtered_ref_kbs\n",
    "\n",
    "\n",
    "filtered_ref_kbs = filter_ref_kb_by_top_n_wikiproperties(ref_kbs, popular_properties, 200)\n",
    "print(f\"Num filtered properties: {len(filtered_ref_kbs[0]['properties'])}\")\n",
    "filtered_ref_kbs[0]['properties']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🪬 Define Evaluation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ValidatedProperty(BaseModel):\n",
    "    property_name: str\n",
    "    property_value: Union[List[str], str, int, Dict[str, str]]\n",
    "    property_name_is_valid: bool = Field(\n",
    "      ...,\n",
    "        description=\"A predicted property name is valid if is semantically close \" +\n",
    "                    \"to a property name in the reference knowledge base.\",\n",
    "    )\n",
    "    property_value_is_valid: bool = Field(\n",
    "      ...,\n",
    "        description=\"Whether the property value is generally valid, judged against the \" +\n",
    "                    \"reference knowledge base.\",\n",
    "    )\n",
    "    error_message: Optional[str] = Field(\n",
    "        None, description=\"The error message if either property_name and/or property_value is not valid.\"\n",
    "    )\n",
    "    matching_reference_property: Optional[str] = Field(\n",
    "        ...,\n",
    "        description=\"If the predicted property_name is valid, \" +\n",
    "                    \"provide the corresponding property_name in the reference knowledge base.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class KnowledgeBase(BaseModel):\n",
    "    entity_label: str\n",
    "    properties: Dict[str, Any]\n",
    "\n",
    "\n",
    "class EvaluationKB(BaseModel):\n",
    "    predicted_knowledge_base: KnowledgeBase = Field(\n",
    "        ...,\n",
    "        description=\"The predicted knowledge base that must be evaluated against the reference.\"\n",
    "    )\n",
    "    reference_knowledge_base: KnowledgeBase = Field(\n",
    "        ..., \n",
    "        description=\"The reference knowledge base used for evaluating prediction.\"\n",
    "    )\n",
    "    validated_properties: List[ValidatedProperty] = []\n",
    "\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_properties(self, context: str) -> \"EvaluationKB\":\n",
    "\n",
    "        existing_pred_properties = list(self.predicted_knowledge_base.properties.keys())\n",
    "        existing_ref_properties = list(self.reference_knowledge_base.properties.keys())\n",
    "\n",
    "        for predicted_property in self.predicted_knowledge_base.properties:\n",
    "\n",
    "            # EVALUATE ONE PROPERTY\n",
    "            resp: ValidatedProperty = client.chat.completions.create(\n",
    "                response_model=ValidatedProperty,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Using your knowledge of the world and the given \" +\n",
    "                        \"reference knowledge base, is the following property valid? \" +\n",
    "                        f\"\\nPredicted Property: {predicted_property}\" +\n",
    "                        f\"\\n\\nReference Knowledge Base: {self.reference_knowledge_base}\"\n",
    "                    }\n",
    "                ],\n",
    "                validation_context={\n",
    "                    \"existing_ref_properties\": existing_ref_properties,\n",
    "                    \"existing_pred_properties\": existing_pred_properties,\n",
    "                },\n",
    "                max_retries=3,\n",
    "                model=MODEL,\n",
    "            )\n",
    "\n",
    "            self.validated_properties.append(resp)\n",
    "        return self\n",
    "\n",
    "    @field_validator('validated_properties', mode='after')\n",
    "    @classmethod\n",
    "    def assert_all_properties_validated(cls, validation_properties: List[ValidatedProperty], info: ValidationInfo):\n",
    "        existing_pred_properties = info.context.get(\"existing_pred_properties\")\n",
    "        if len(validation_properties) != len(existing_pred_properties):\n",
    "            raise ValueError(\n",
    "                \"Number of properties validated does not match number of properties in the prediction knowledge base. \" +\n",
    "                \"Number of properties validated: {len(validation_properties)}, \" +\n",
    "                f\"Number of properties in the text: {len(existing_pred_properties)}\"\n",
    "                )\n",
    "        return validation_properties\n",
    "\n",
    "    @field_validator('validated_properties', mode='after')\n",
    "    @classmethod\n",
    "    def assert_matching_ref_in_ref_kb(cls, validation_properties: List[ValidatedProperty], info: ValidationInfo):\n",
    "        '''\n",
    "        Make sure that the reference property that is linked to the prediction \n",
    "        actually exists in the reference knowledge base.\n",
    "        '''\n",
    "        existing_ref_properties = info.context.get(\"existing_ref_properties\")\n",
    "        for prop in validation_properties:\n",
    "            if prop.property_name_is_valid:\n",
    "                if prop.matching_reference_property not in existing_ref_properties:\n",
    "                    raise ValueError(\n",
    "                        f\"The predicted property name {prop.property_name} was marked valid but the matching_reference_property \" +\n",
    "                        f\"{prop.matching_reference_property} does not exist in the reference knowledge base.\"\n",
    "                    )\n",
    "        return validation_properties\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for idx in range(len(pred_kbs)):\n",
    "\n",
    "    # 🚨 NOTE: take the text data OUT! It'll fill the prompt otherwise\n",
    "    chunked_content = filtered_ref_kbs[idx].pop('chunked_content', None) # take the text out \n",
    "    QID = filtered_ref_kbs[idx].pop('QID', None)\n",
    "    eval_info = {\n",
    "        'predicted_knowledge_base': pred_kbs[idx],\n",
    "        'reference_knowledge_base': filtered_ref_kbs[idx],\n",
    "    }\n",
    "    try:\n",
    "        result = EvaluationKB(**eval_info)\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to evaluate at KB {idx} with error {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to f'../../data/evaluation_results.jsonl\n"
     ]
    }
   ],
   "source": [
    "results_json = [r.model_dump() for r in results]\n",
    "save_jsonl(results_json, '../../data/evaluation_results.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at our Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = read_jsonl('../../data/evaluation_results.jsonl')\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visually_verify_results(result: Dict):\n",
    "    '''Look at the validation KB, prediction KB, and reference KB side-by-side'''\n",
    "    print(f\"Validating for entity {result['validated_knowledge_base']['entity_label']}\")\n",
    "\n",
    "    for val in result['validated_knowledge_base']['properties']:\n",
    "        print('\\n--------------------------')\n",
    "        print(f\"🤖 Validated Property: {json.dumps(val, indent=4)}\")\n",
    "\n",
    "        matching_pred_property = result['predicted_knowledge_base']['properties'][val['property_name']]\n",
    "        print(f\"What does the prediction KB say? \\n{matching_pred_property}\")\n",
    "\n",
    "        # if the predicted property was valid, get the reference the LLM points to\n",
    "        if val['property_name_is_valid'] is True:  \n",
    "            matching_ref_property = result['reference_knowledge_base']['properties'][val['matching_reference_property']]\n",
    "            print(f\"✅What does the reference KB say? \\n{val['matching_reference_property']}: {matching_ref_property}\")\n",
    "        else:\n",
    "            print(f\"🚨The LLM said this one is not in the reference KB!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating for entity Tim Berners-Lee\n",
      "\n",
      "--------------------------\n",
      "🤖 Validated Property: {\n",
      "    \"property_name\": \"Full Name\",\n",
      "    \"property_value\": \"Sir Timothy John Berners-Lee\",\n",
      "    \"property_name_is_valid\": false,\n",
      "    \"property_value_is_valid\": true,\n",
      "    \"error_message\": null,\n",
      "    \"matching_reference_property\": \"given name\"\n",
      "}\n",
      "What does the prediction KB say? \n",
      "Sir Timothy John Berners-Lee\n",
      "🚨The LLM said this one is not in the reference KB!\n",
      "\n",
      "--------------------------\n",
      "🤖 Validated Property: {\n",
      "    \"property_name\": \"Date of Birth\",\n",
      "    \"property_value\": \"8 June 1955\",\n",
      "    \"property_name_is_valid\": true,\n",
      "    \"property_value_is_valid\": true,\n",
      "    \"error_message\": null,\n",
      "    \"matching_reference_property\": \"date of birth\"\n",
      "}\n",
      "What does the prediction KB say? \n",
      "8 June 1955\n",
      "✅What does the reference KB say? \n",
      "date of birth: ['+1955-06-08T00:00:00Z', '+1955-00-00T00:00:00Z']\n",
      "\n",
      "--------------------------\n",
      "🤖 Validated Property: {\n",
      "    \"property_name\": \"Nationality\",\n",
      "    \"property_value\": \"English\",\n",
      "    \"property_name_is_valid\": false,\n",
      "    \"property_value_is_valid\": true,\n",
      "    \"error_message\": null,\n",
      "    \"matching_reference_property\": \"country of citizenship\"\n",
      "}\n",
      "What does the prediction KB say? \n",
      "English\n",
      "🚨The LLM said this one is not in the reference KB!\n",
      "\n",
      "--------------------------\n",
      "🤖 Validated Property: {\n",
      "    \"property_name\": \"Occupation\",\n",
      "    \"property_value\": [\n",
      "        \"Computer Scientist\",\n",
      "        \"Professor\"\n",
      "    ],\n",
      "    \"property_name_is_valid\": false,\n",
      "    \"property_value_is_valid\": false,\n",
      "    \"error_message\": null,\n",
      "    \"matching_reference_property\": \"occupation\"\n",
      "}\n",
      "What does the prediction KB say? \n",
      "['Computer Scientist', 'Professor']\n",
      "🚨The LLM said this one is not in the reference KB!\n",
      "\n",
      "--------------------------\n",
      "🤖 Validated Property: {\n",
      "    \"property_name\": \"Known For\",\n",
      "    \"property_value\": \"Inventing the World Wide Web, HTML, URL system, HTTP\",\n",
      "    \"property_name_is_valid\": false,\n",
      "    \"property_value_is_valid\": false,\n",
      "    \"error_message\": null,\n",
      "    \"matching_reference_property\": null\n",
      "}\n",
      "What does the prediction KB say? \n",
      "Inventing the World Wide Web, HTML, URL system, HTTP\n",
      "🚨The LLM said this one is not in the reference KB!\n"
     ]
    }
   ],
   "source": [
    "visually_verify_results(results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_none(s):\n",
    "    if s is not None:\n",
    "        return None if s.lower() in ['none', 'null'] else s\n",
    "    return s\n",
    "\n",
    "def calc_metrics(result: Dict, metrics: Dict[str, int] = None) -> Dict[str, int]:\n",
    "    '''Calculate TP, FP, FN for a given result. Add to metrics dict if provided'''\n",
    "    if metrics is None:\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "    else:\n",
    "        tp, fp, fn = metrics['tp'], metrics['fp'], metrics['fn']\n",
    "\n",
    "    reference_properties_caught = []\n",
    "    for val in result['validated_knowledge_base']['properties']:\n",
    "\n",
    "        # true positive\n",
    "        if val['property_name_is_valid'] is True:  \n",
    "            tp += 1\n",
    "            reference_properties_caught.append(val['matching_reference_property'])\n",
    "        # false positive\n",
    "        elif val['property_name_is_valid'] is False and (parse_none(val['matching_reference_property']) is None):\n",
    "            fp += 1\n",
    "\n",
    "    # false negative -- get all the reference properties that WEREN'T predicted\n",
    "    for ref_prop_name in result['reference_knowledge_base']['properties'].keys():\n",
    "        if ref_prop_name not in reference_properties_caught:\n",
    "            fn += 1\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1_score = (2 * (precision * recall)) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    print(\"----------\")\n",
    "    print(f\"Validating for entity {result['validated_knowledge_base']['entity_label']}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "    print(\"----------\")\n",
    "    return {'tp': tp, 'fp': fp, 'fn': fn}\n",
    "\n",
    "metrics = calc_metrics(results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initial out for evaluation:\n",
    "\n",
    "{'predicted_knowledge_base': {'entity_label': 'Alexei Navalny',\n",
    "  'properties': {'Name': 'Alexei Navalny',\n",
    "   'Full Name': 'Alexei Anatolyevich Navalny',\n",
    "   'Date of Birth': '4 June 1976',\n",
    "   'Date of Death': '16 February 2024',\n",
    "   'Citizenship': 'Russian',\n",
    "   'Occupation': 'Politician and Anti-corruption activist',\n",
    "   'Founded Project': ['RosYama'],\n",
    "   'Launched Project': ['Anti-Corruption Foundation (FBK)'],\n",
    "   'Title': 'Investigation and Legal Cases',\n",
    "   'Description': 'Details about investigations and legal cases involving Alexei Navalny.',\n",
    "   'Date of death': '16 February 2024',\n",
    "   'Place of death': 'Yamalo-Nenets in Western Siberia',\n",
    "   'stated by': 'Alexei Kudrin, Boris Akunin, Mikhail Khodorkovsky, Vladimir Zhirinovsky, Marie Harf, Catherine Ashton, Andreas Schockenhoff, The New York Times, Alexei Venediktov, Levada Center, Leonid Volkov, Alexander Verkhovskiy',\n",
    "   'criticised by': ['Vladimir Zhirinovsky',\n",
    "    'United States Department of State Deputy Spokesperson Marie Harf',\n",
    "    'European Union High Representative Catherine Ashton',\n",
    "    \"Andreas Schockenhoff, Germany's Commissioner for German-Russian Coordination\",\n",
    "    'Levada Center experts',\n",
    "    'Alexander Verkhovskiy, head of the Moscow-based SOVA hate crimes monitor'],\n",
    "   'supported by': 'Boris Nemtsov Foundation for Freedom, Geneva Summit for Human Rights and Democracy, Time magazine, Casimir Pulaski Foundation, European Parliament, M100 Media Award, Daniel Roher',\n",
    "   'Family': ['Married to Yulia Abrosimova',\n",
    "    'Had two children: daughter Darya (Dasha) Navalnaya and son Zakhar',\n",
    "    'Daughter began undergraduate studies at Stanford University in September 2019'],\n",
    "   'Residence': 'Lived primarily in a three-room apartment in Maryino District in southeast Moscow since 1998',\n",
    "   'Religion': 'Became a member of the Russian Orthodox Church'}},\n",
    " 'reference_knowledge_base': {'entity_label': 'Alexei Navalny',\n",
    "  'properties': {'member of': ['Russian Opposition Coordination Council',\n",
    "    'Yale World Fellows'],\n",
    "   'sex or gender': ['male'],\n",
    "   'educated at': ['Finance University under the Government of the Russian Federation',\n",
    "    'Yale University',\n",
    "    \"Peoples' Friendship University of Russia\",\n",
    "    'Yale World Fellows'],\n",
    "   'image': ['Alexey Navalny (cropped) 1.jpg'],\n",
    "   'member of political party': ['Yabloko',\n",
    "    'Progress Party',\n",
    "    'Russia of the Future'],\n",
    "   'Commons category': ['Alexey Navalny'],\n",
    "   'employer': ['Anti-Corruption Foundation', 'Aeroflot'],\n",
    "   'date of birth': ['+1976-06-04T00:00:00Z'],\n",
    "   'religion or worldview': ['Eastern Orthodoxy'],\n",
    "   'country of citizenship': ['Soviet Union', 'Russia'],\n",
    "   'field of work': ['politics', 'jurisprudence'],\n",
    "   'place of birth': ['Butyn'],\n",
    "   'instance of': ['human'],\n",
    "   'described by source': ['Lentapedia', 'Navalny'],\n",
    "   'official website URL': ['https://navalny.com'],\n",
    "   'given name': ['Alexey'],\n",
    "   'significant event': ['Yves Rocher case',\n",
    "    'poisoning of Alexei Navalny',\n",
    "    'Kirovles trial',\n",
    "    'incarceration',\n",
    "    'poisoning of Alexei Navalny',\n",
    "    'death of Alexei Navalny'],\n",
    "   'sibling': ['Oleg Navalny'],\n",
    "   'languages spoken, written or signed': ['Russian', 'English'],\n",
    "   'name in native language': [\"{'text': 'Алексей Анатольевич Навальный', 'language': 'ru'}\"],\n",
    "   'spouse': ['Yulia Navalnaya'],\n",
    "   'ISNI': ['0000000377416015', '0000000410082812'],\n",
    "   \"topic's main category\": ['Category:Alexei Navalny'],\n",
    "   'on focus list of Wikimedia project': ['WikiProject Human Rights'],\n",
    "   'family name': ['Navalny'],\n",
    "   'social media followers': ['+2355803',\n",
    "    '+2236418',\n",
    "    '+6460000',\n",
    "    '+2673187',\n",
    "    '+2980696',\n",
    "    '+6370000'],\n",
    "   'position held': ['Leader of Russia of the Future',\n",
    "    'Leader of Russia of the Future'],\n",
    "   'award received': ['Person of the Year',\n",
    "    'FP Top 100 Global Thinkers',\n",
    "    'Prize of the Platform of European Memory and Conscience',\n",
    "    'Time 100',\n",
    "    'Gold Play Button',\n",
    "    'Courage Award',\n",
    "    'Boris Nemtsov Prize',\n",
    "    'Knight of Freedom Award',\n",
    "    'Sakharov Prize',\n",
    "    'M100 Media Award',\n",
    "    'The BOBs',\n",
    "    'Silver Play Button',\n",
    "    'Civil Courage Prize',\n",
    "    'Günter Walraff award',\n",
    "    'Bambi Award'],\n",
    "   'height': ['+1.89'],\n",
    "   'occupation': ['politician',\n",
    "    'lawyer',\n",
    "    'activist',\n",
    "    'blogger',\n",
    "    'public figure',\n",
    "    'activist shareholder',\n",
    "    'YouTuber',\n",
    "    'film director',\n",
    "    'announcer',\n",
    "    'screenwriter',\n",
    "    'entrepreneur',\n",
    "    'political prisoner',\n",
    "    'jurist',\n",
    "    'prisoner of conscience'],\n",
    "   'child': ['Darya Navalnaya', 'Zakhar Navalny'],\n",
    "   'date of death': ['+2024-02-16T00:00:00Z'],\n",
    "   'place of death': ['Corrective colony No. 3, YaNAO'],\n",
    "   'described at URL': ['http://dbpedia.org/resource/Alexei_Navalny'],\n",
    "   'mother': ['Lyudmila Navalnaya'],\n",
    "   'father': ['Anatoly Navalny']}},\n",
    " 'validated_knowledge_base': {'entity_label': 'Alexei Navalny',\n",
    "  'properties': [{'property_name': 'Name',\n",
    "    'property_value': 'Alexei Navalny',\n",
    "    'is_valid': True,\n",
    "    'error_message': None,\n",
    "    'matching_reference_property': 'name in native language'},\n",
    "   {'property_name': 'Full Name',\n",
    "    'property_value': 'Alexei Anatolyevich Navalny',\n",
    "    'is_valid': True,\n",
    "    'error_message': None,\n",
    "    'matching_reference_property': 'given name'},\n",
    "   {'property_name': 'Date of Birth',\n",
    "    'property_value': '4 June 1976',\n",
    "    'is_valid': True,\n",
    "    'error_message': None,\n",
    "    'matching_reference_property': 'date of birth'},\n",
    "   {'property_name': 'Date of Death',\n",
    "    'property_value': '16 February 2024',\n",
    "    'is_valid': True,\n",
    "    'error_message': None,\n",
    "    'matching_reference_property': 'date of death'},\n",
    "   {'property_name': 'Citizenship',\n",
    "    'property_value': 'Russian',\n",
    "    'is_valid': True,\n",
    "    'error_message': None,\n",
    "    'matching_reference_property': 'country of citizenship'},\n",
    "   {'property_name': 'Occupation',\n",
    "    'property_value': 'Politician and Anti-corruption activist',\n",
    "    'is_valid': True,\n",
    "    'error_message': None,\n",
    "    'matching_reference_property': 'occupation'},\n",
    "   {'property_name': 'Founded Project',\n",
    "    'property_value': ['RosYama'],\n",
    "    'is_valid': False,\n",
    "    'error_message': \"The founded project 'RosYama' does not match any reference property.\",\n",
    "    'matching_reference_property': None},\n",
    "   {'property_name': 'Launched Project',\n",
    "    'property_value': ['Anti-Corruption Foundation (FBK)'],\n",
    "    'is_valid': False,\n",
    "    'error_message': \"The launched project 'Anti-Corruption Foundation (FBK)' does not match any reference property.\",\n",
    "    'matching_reference_property': None},\n",
    "   {'property_name': 'Title',\n",
    "    'property_value': 'Investigation and Legal Cases',\n",
    "    'is_valid': False,\n",
    "    'error_message': \"The title 'Investigation and Legal Cases' does not match any reference property.\",\n",
    "    'matching_reference_property': None},\n",
    "   {'property_name': 'Description',\n",
    "    'property_value': 'Details about investigations and legal cases involving Alexei Navalny.',\n",
    "    'is_valid': False,\n",
    "    'error_message': 'The description does not match any reference property.',\n",
    "    'matching_reference_property': None},\n",
    "   {'property_name': 'Date of death',\n",
    "    'property_value': '16 February 2024',\n",
    "    'is_valid': True,\n",
    "    'error_message': None,\n",
    "    'matching_reference_property': 'date of death'},\n",
    "   {'property_name': 'Place of death',\n",
    "    'property_value': 'Yamalo-Nenets in Western Siberia',\n",
    "    'is_valid': False,\n",
    "    'error_message': \"The place of death 'Yamalo-Nenets in Western Siberia' does not match the reference property 'Corrective colony No. 3, YaNAO'.\",\n",
    "    'matching_reference_property': None},\n",
    "   {'property_name': 'stated by',\n",
    "    'property_value': ['Alexei Kudrin',\n",
    "     'Boris Akunin',\n",
    "     'Mikhail Khodorkovsky',\n",
    "     'Vladimir Zhirinovsky',\n",
    "     'Marie Harf',\n",
    "     'Catherine Ashton',\n",
    "     'Andreas Schockenhoff',\n",
    "     'The New York Times',\n",
    "     'Alexei Venediktov',\n",
    "     'Levada Center',\n",
    "     'Leonid Volkov',\n",
    "     'Alexander Verkhovskiy'],\n",
    "    'is_valid': True,\n",
    "    'error_message': None,\n",
    "    'matching_reference_property': 'described by source'},\n",
    "   {'property_name': 'criticised by',\n",
    "    'property_value': ['Vladimir Zhirinovsky',\n",
    "     'United States Department of State Deputy Spokesperson Marie Harf',\n",
    "     'European Union High Representative Catherine Ashton',\n",
    "     \"Andreas Schockenhoff, Germany's Commissioner for German-Russian Coordination\",\n",
    "     'Levada Center experts',\n",
    "     'Alexander Verkhovskiy, head of the Moscow-based SOVA hate crimes monitor'],\n",
    "    'is_valid': False,\n",
    "    'error_message': 'The list of critics does not match any reference property.',\n",
    "    'matching_reference_property': None},\n",
    "   {'property_name': 'supported by',\n",
    "    'property_value': 'Boris Nemtsov Foundation for Freedom, Geneva Summit for Human Rights and Democracy, Time magazine, Casimir Pulaski Foundation, European Parliament, M100 Media Award, Daniel Roher',\n",
    "    'is_valid': False,\n",
    "    'error_message': 'The list of supporters does not match any reference property.',\n",
    "    'matching_reference_property': None},\n",
    "   {'property_name': 'Family',\n",
    "    'property_value': ['Married to Yulia Abrosimova',\n",
    "     'Had two children: daughter Darya (Dasha) Navalnaya and son Zakhar',\n",
    "     'Daughter began undergraduate studies at Stanford University in September 2019'],\n",
    "    'is_valid': False,\n",
    "    'error_message': 'The family information does not match any reference property.',\n",
    "    'matching_reference_property': None},\n",
    "   {'property_name': 'Residence',\n",
    "    'property_value': 'Lived primarily in a three-room apartment in Maryino District in southeast Moscow since 1998',\n",
    "    'is_valid': False,\n",
    "    'error_message': 'The residence information does not match any reference property.',\n",
    "    'matching_reference_property': None},\n",
    "   {'property_name': 'Religion',\n",
    "    'property_value': 'Became a member of the Russian Orthodox Church',\n",
    "    'is_valid': False,\n",
    "    'error_message': 'The religion information does not match any reference property.',\n",
    "    'matching_reference_property': None}]}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Validating for entity Alexei Navalny\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Name\",\n",
    "    \"property_value\": \"Alexei Navalny\",\n",
    "    \"is_valid\": true,\n",
    "    \"error_message\": null,\n",
    "    \"matching_reference_property\": \"name in native language\"\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Alexei Navalny\n",
    "✅What does the reference KB say? \n",
    "name in native language: [\"{'text': 'Алексей Анатольевич Навальный', 'language': 'ru'}\"]\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Full Name\",\n",
    "    \"property_value\": \"Alexei Anatolyevich Navalny\",\n",
    "    \"is_valid\": true,\n",
    "    \"error_message\": null,\n",
    "    \"matching_reference_property\": \"given name\"\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Alexei Anatolyevich Navalny\n",
    "✅What does the reference KB say? \n",
    "given name: ['Alexey']\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Date of Birth\",\n",
    "    \"property_value\": \"4 June 1976\",\n",
    "    \"is_valid\": true,\n",
    "    \"error_message\": null,\n",
    "    \"matching_reference_property\": \"date of birth\"\n",
    "}\n",
    "What does the prediction KB say? \n",
    "4 June 1976\n",
    "✅What does the reference KB say? \n",
    "date of birth: ['+1976-06-04T00:00:00Z']\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Date of Death\",\n",
    "    \"property_value\": \"16 February 2024\",\n",
    "    \"is_valid\": true,\n",
    "    \"error_message\": null,\n",
    "    \"matching_reference_property\": \"date of death\"\n",
    "}\n",
    "What does the prediction KB say? \n",
    "16 February 2024\n",
    "✅What does the reference KB say? \n",
    "date of death: ['+2024-02-16T00:00:00Z']\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Citizenship\",\n",
    "    \"property_value\": \"Russian\",\n",
    "    \"is_valid\": true,\n",
    "    \"error_message\": null,\n",
    "    \"matching_reference_property\": \"country of citizenship\"\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Russian\n",
    "✅What does the reference KB say? \n",
    "country of citizenship: ['Soviet Union', 'Russia']\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Occupation\",\n",
    "    \"property_value\": \"Politician and Anti-corruption activist\",\n",
    "    \"is_valid\": true,\n",
    "    \"error_message\": null,\n",
    "    \"matching_reference_property\": \"occupation\"\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Politician and Anti-corruption activist\n",
    "✅What does the reference KB say? \n",
    "occupation: ['politician', 'lawyer', 'activist', 'blogger', 'public figure', 'activist shareholder', 'YouTuber', 'film director', 'announcer', 'screenwriter', 'entrepreneur', 'political prisoner', 'jurist', 'prisoner of conscience']\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Founded Project\",\n",
    "    \"property_value\": [\n",
    "        \"RosYama\"\n",
    "    ],\n",
    "    \"is_valid\": false,\n",
    "    \"error_message\": \"The founded project 'RosYama' does not match any reference property.\",\n",
    "    \"matching_reference_property\": null\n",
    "}\n",
    "What does the prediction KB say? \n",
    "['RosYama']\n",
    "🚨The LLM said this one is not in the reference KB!\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Launched Project\",\n",
    "    \"property_value\": [\n",
    "        \"Anti-Corruption Foundation (FBK)\"\n",
    "    ],\n",
    "    \"is_valid\": false,\n",
    "    \"error_message\": \"The launched project 'Anti-Corruption Foundation (FBK)' does not match any reference property.\",\n",
    "    \"matching_reference_property\": null\n",
    "}\n",
    "What does the prediction KB say? \n",
    "['Anti-Corruption Foundation (FBK)']\n",
    "🚨The LLM said this one is not in the reference KB!\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Title\",\n",
    "    \"property_value\": \"Investigation and Legal Cases\",\n",
    "    \"is_valid\": false,\n",
    "    \"error_message\": \"The title 'Investigation and Legal Cases' does not match any reference property.\",\n",
    "    \"matching_reference_property\": null\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Investigation and Legal Cases\n",
    "🚨The LLM said this one is not in the reference KB!\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Description\",\n",
    "    \"property_value\": \"Details about investigations and legal cases involving Alexei Navalny.\",\n",
    "    \"is_valid\": false,\n",
    "    \"error_message\": \"The description does not match any reference property.\",\n",
    "    \"matching_reference_property\": null\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Details about investigations and legal cases involving Alexei Navalny.\n",
    "🚨The LLM said this one is not in the reference KB!\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Date of death\",\n",
    "    \"property_value\": \"16 February 2024\",\n",
    "    \"is_valid\": true,\n",
    "    \"error_message\": null,\n",
    "    \"matching_reference_property\": \"date of death\"\n",
    "}\n",
    "What does the prediction KB say? \n",
    "16 February 2024\n",
    "✅What does the reference KB say? \n",
    "date of death: ['+2024-02-16T00:00:00Z']\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Place of death\",\n",
    "    \"property_value\": \"Yamalo-Nenets in Western Siberia\",\n",
    "    \"is_valid\": false,\n",
    "    \"error_message\": \"The place of death 'Yamalo-Nenets in Western Siberia' does not match the reference property 'Corrective colony No. 3, YaNAO'.\",\n",
    "    \"matching_reference_property\": null\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Yamalo-Nenets in Western Siberia\n",
    "🚨The LLM said this one is not in the reference KB!\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"stated by\",\n",
    "    \"property_value\": [\n",
    "        \"Alexei Kudrin\",\n",
    "        \"Boris Akunin\",\n",
    "        \"Mikhail Khodorkovsky\",\n",
    "        \"Vladimir Zhirinovsky\",\n",
    "        \"Marie Harf\",\n",
    "        \"Catherine Ashton\",\n",
    "        \"Andreas Schockenhoff\",\n",
    "        \"The New York Times\",\n",
    "        \"Alexei Venediktov\",\n",
    "        \"Levada Center\",\n",
    "        \"Leonid Volkov\",\n",
    "        \"Alexander Verkhovskiy\"\n",
    "    ],\n",
    "    \"is_valid\": true,\n",
    "    \"error_message\": null,\n",
    "    \"matching_reference_property\": \"described by source\"\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Alexei Kudrin, Boris Akunin, Mikhail Khodorkovsky, Vladimir Zhirinovsky, Marie Harf, Catherine Ashton, Andreas Schockenhoff, The New York Times, Alexei Venediktov, Levada Center, Leonid Volkov, Alexander Verkhovskiy\n",
    "✅What does the reference KB say? \n",
    "described by source: ['Lentapedia', 'Navalny']\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"criticised by\",\n",
    "    \"property_value\": [\n",
    "        \"Vladimir Zhirinovsky\",\n",
    "        \"United States Department of State Deputy Spokesperson Marie Harf\",\n",
    "        \"European Union High Representative Catherine Ashton\",\n",
    "        \"Andreas Schockenhoff, Germany's Commissioner for German-Russian Coordination\",\n",
    "        \"Levada Center experts\",\n",
    "        \"Alexander Verkhovskiy, head of the Moscow-based SOVA hate crimes monitor\"\n",
    "    ],\n",
    "    \"is_valid\": false,\n",
    "    \"error_message\": \"The list of critics does not match any reference property.\",\n",
    "    \"matching_reference_property\": null\n",
    "}\n",
    "What does the prediction KB say? \n",
    "['Vladimir Zhirinovsky', 'United States Department of State Deputy Spokesperson Marie Harf', 'European Union High Representative Catherine Ashton', \"Andreas Schockenhoff, Germany's Commissioner for German-Russian Coordination\", 'Levada Center experts', 'Alexander Verkhovskiy, head of the Moscow-based SOVA hate crimes monitor']\n",
    "🚨The LLM said this one is not in the reference KB!\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"supported by\",\n",
    "    \"property_value\": \"Boris Nemtsov Foundation for Freedom, Geneva Summit for Human Rights and Democracy, Time magazine, Casimir Pulaski Foundation, European Parliament, M100 Media Award, Daniel Roher\",\n",
    "    \"is_valid\": false,\n",
    "    \"error_message\": \"The list of supporters does not match any reference property.\",\n",
    "    \"matching_reference_property\": null\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Boris Nemtsov Foundation for Freedom, Geneva Summit for Human Rights and Democracy, Time magazine, Casimir Pulaski Foundation, European Parliament, M100 Media Award, Daniel Roher\n",
    "🚨The LLM said this one is not in the reference KB!\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Family\",\n",
    "    \"property_value\": [\n",
    "        \"Married to Yulia Abrosimova\",\n",
    "        \"Had two children: daughter Darya (Dasha) Navalnaya and son Zakhar\",\n",
    "        \"Daughter began undergraduate studies at Stanford University in September 2019\"\n",
    "    ],\n",
    "    \"is_valid\": false,\n",
    "    \"error_message\": \"The family information does not match any reference property.\",\n",
    "    \"matching_reference_property\": null\n",
    "}\n",
    "What does the prediction KB say? \n",
    "['Married to Yulia Abrosimova', 'Had two children: daughter Darya (Dasha) Navalnaya and son Zakhar', 'Daughter began undergraduate studies at Stanford University in September 2019']\n",
    "🚨The LLM said this one is not in the reference KB!\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Residence\",\n",
    "    \"property_value\": \"Lived primarily in a three-room apartment in Maryino District in southeast Moscow since 1998\",\n",
    "    \"is_valid\": false,\n",
    "    \"error_message\": \"The residence information does not match any reference property.\",\n",
    "    \"matching_reference_property\": null\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Lived primarily in a three-room apartment in Maryino District in southeast Moscow since 1998\n",
    "🚨The LLM said this one is not in the reference KB!\n",
    "\n",
    "--------------------------\n",
    "🤖 Validated Property: {\n",
    "    \"property_name\": \"Religion\",\n",
    "    \"property_value\": \"Became a member of the Russian Orthodox Church\",\n",
    "    \"is_valid\": false,\n",
    "    \"error_message\": \"The religion information does not match any reference property.\",\n",
    "    \"matching_reference_property\": null\n",
    "}\n",
    "What does the prediction KB say? \n",
    "Became a member of the Russian Orthodox Church\n",
    "🚨The LLM said this one is not in the reference KB!\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instructor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
